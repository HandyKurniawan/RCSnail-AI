{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from commons.configuration_manager import ConfigurationManager\n",
    "from src.learning.training.label_collector import LabelCollector\n",
    "from src.learning.training.training_file_reader import TrainingFileReader\n",
    "from src.learning.training.training_transformer import TrainingTransformer\n",
    "from src.learning.models import create_cnn, create_mlp, create_multi_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_manager = ConfigurationManager()\n",
    "config = config_manager.config\n",
    "\n",
    "reader = TrainingFileReader(path_to_training='../../training/laps/')\n",
    "transformer = TrainingTransformer(config)\n",
    "collector = LabelCollector()\n",
    "\n",
    "# axis=2 for frames, axis=0 for telem and diffs\n",
    "def memory_creator(instance, memory, length=4, interval=2, axis=2):\n",
    "    memory.append(instance)\n",
    "    \n",
    "    near_memory = memory[::-interval]\n",
    "    if len(near_memory) < length:\n",
    "        return None\n",
    "    \n",
    "    if len(memory) >= length * interval:\n",
    "        memory.pop(0)\n",
    "        \n",
    "    return np.concatenate(near_memory, axis=axis)\n",
    "\n",
    "\n",
    "def read_stored_data(filename):\n",
    "    df = reader.read_telemetry_as_csv(filename + '.csv')\n",
    "    telemetry = collector.collect_numeric_inputs(df)\n",
    "    diffs = collector.collect_expert_labels(df)\n",
    "\n",
    "    frames = reader.read_training_video(filename + '.avi')\n",
    "    resized_frames_np = transformer.resize_video_for_training(frames)\n",
    "\n",
    "    return resized_frames_np, telemetry, diffs\n",
    "\n",
    "\n",
    "def prep_full_mem_datas(frames, telemetry, diffs, length, interval):    \n",
    "    mem_slice_frames = []\n",
    "    mem_slice_telemetry = []\n",
    "    \n",
    "    mem_frames = []\n",
    "    for frame in frames:\n",
    "        mem_frame = memory_creator(frame, mem_slice_frames, length=length, interval=interval, axis=2)\n",
    "\n",
    "        if mem_frame is not None:\n",
    "            mem_frames.append(mem_frame)\n",
    "    mem_frames_np = np.array(mem_frames)\n",
    "    \n",
    "    mem_telemetry = []\n",
    "    for index, telem in telemetry.iterrows():\n",
    "        mem_telem = memory_creator(telem, mem_slice_telemetry, length=length, interval=interval, axis=0)\n",
    "\n",
    "        if mem_telem is not None:\n",
    "            mem_telemetry.append(mem_telem)\n",
    "    mem_telemetry_np = np.array(mem_telemetry)\n",
    "    \n",
    "    mem_diffs = diffs\n",
    "    len_diff = diffs.shape[0] - mem_frames_np.shape[0]\n",
    "    if len_diff > 0:\n",
    "        mem_diffs = mem_diffs.iloc[len_diff:]\n",
    "    mem_diffs_np = mem_diffs.to_numpy()\n",
    "    \n",
    "    assert mem_frames_np.shape[0] == mem_telemetry_np.shape[0] == mem_diffs_np.shape[0], \"Lengths differ!\"\n",
    "    return mem_frames_np, mem_telemetry_np, mem_diffs_np\n",
    "\n",
    "\n",
    "def prep_mem_datas(frames, telemetry, diffs, length, interval):\n",
    "    mem_telemetry = telemetry\n",
    "    mem_diffs = diffs\n",
    "    \n",
    "    memory = []\n",
    "    mem_frames = []\n",
    "    for frame in frames:\n",
    "        mem_frame = memory_creator(frame, memory, length=length, interval=interval, axis=2)\n",
    "\n",
    "        if mem_frame is not None:\n",
    "            mem_frames.append(mem_frame)\n",
    "\n",
    "    mem_frames_np = np.array(mem_frames)\n",
    "\n",
    "    len_diff = mem_telemetry.shape[0] - mem_frames_np.shape[0]\n",
    "    if len_diff > 0:\n",
    "        mem_telemetry = mem_telemetry.iloc[len_diff:]\n",
    "        mem_diffs = mem_diffs.iloc[len_diff:]\n",
    "    \n",
    "    mem_telemetry_np = mem_telemetry.to_numpy()\n",
    "    mem_diffs_np = mem_diffs.to_numpy()\n",
    "\n",
    "    return mem_frames_np, mem_telemetry_np, mem_diffs_np\n",
    "\n",
    "\n",
    "def plot_stuff(title, plot_elems, figsize=(18, 10)):\n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    plt.title(title)\n",
    "    #plt.ylabel('dunno')\n",
    "    plt.xlabel('Epoch')\n",
    "    x = np.arange(0, len(plot_elems[0]['data']), 1)\n",
    "    \n",
    "    for plot_elem in plot_elems:\n",
    "        plt.errorbar(x, plot_elem['data'], yerr=plot_elem['error'], label=plot_elem['label'], alpha=plot_elem['alpha'], fmt='-o', capsize=5)\n",
    "\n",
    "    plt.grid(axis='x')\n",
    "    plt.legend(loc='best', prop={'size': 15})\n",
    "    plt.show()\n",
    "    plt.savefig('./' + title + '.png')\n",
    "\n",
    "    \n",
    "filenames = ['lap_5_2020_01_24', 'lap_6_2020_01_24', 'lap_7_2020_01_24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, telems, diffs = read_stored_data(filenames[0])\n",
    "mem_frames, mem_telems, mem_diffs = prep_full_mem_datas(*read_stored_data(filenames[0]), 4, 1)\n",
    "\n",
    "print(mem_frames.shape)\n",
    "print(mem_telems.shape)\n",
    "print(mem_diffs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [(1, 1), (4, 1), (8, 1), (16, 1)]\n",
    "datas_list = []\n",
    "\n",
    "for experiment in tqdm(experiments):\n",
    "    frames_mem = None\n",
    "    telemetry_mem = None\n",
    "    diffs_mem = None\n",
    "    \n",
    "    for training_file in filenames:\n",
    "        frames_i, telem_i, diffs_i = prep_full_mem_datas(*read_stored_data(training_file), *experiment)\n",
    "        \n",
    "        if frames_mem is None and telemetry_mem is None and diffs_mem is None:\n",
    "            frames_mem = frames_i\n",
    "            telemetry_mem = telem_i\n",
    "            diffs_mem = diffs_i\n",
    "        else:\n",
    "            frames_mem = np.append(frames_mem, frames_i, axis=0)\n",
    "            telemetry_mem = np.append(telemetry_mem, telem_i, axis=0)\n",
    "            diffs_mem = np.append(diffs_mem, diffs_i, axis=0)\n",
    "        gc.collect()\n",
    "        \n",
    "    datas_list.append((frames_mem, telemetry_mem, diffs_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "verbose = 0\n",
    "\n",
    "results = {}\n",
    "\n",
    "for data in tqdm(datas_list):\n",
    "    result_desc = \"N={}, M={}\".format(*experiments[datas_list.index(data)])\n",
    "    tqdm.write(result_desc)\n",
    "    \n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    for i in tqdm(range(0, 15)):\n",
    "        frames_train, frames_test, telemetry_train, telemetry_test, diffs_train, diffs_test = train_test_split(*data, test_size=0.2)\n",
    "        \n",
    "        mlp = create_mlp(input_shape=telemetry_train[0].shape)\n",
    "        cnn = create_cnn(input_shape=frames_train[0].shape)\n",
    "        multi = create_multi_model(mlp, cnn)\n",
    "    \n",
    "        hist = multi.fit([telemetry_train, frames_train], diffs_train,\n",
    "                        validation_data=([telemetry_test, frames_test], diffs_test),\n",
    "                        epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "        \n",
    "        losses.append(hist.history['loss'])\n",
    "        val_losses.append(hist.history['val_loss'])\n",
    "    \n",
    "        gc.collect()\n",
    "    \n",
    "    mean_losses = [np.mean(i) for i in zip(*losses)]\n",
    "    std_losses = [np.std(i) for i in zip(*losses)]\n",
    "    mean_val_losses = [np.mean(i) for i in zip(*val_losses)]\n",
    "    std_val_losses = [np.std(i) for i in zip(*val_losses)]\n",
    "    \n",
    "    results[result_desc] = mean_losses\n",
    "    results[result_desc + ' std'] = std_losses\n",
    "    results[result_desc + ' val'] = mean_val_losses\n",
    "    results[result_desc + ' val std'] = std_val_losses\n",
    "    \n",
    "    tqdm.write(\"Mean loss per epoch: {}\".format(mean_losses))\n",
    "    tqdm.write(\"Mean validation loss per epoch: {}\".format(mean_val_losses))\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_data = []\n",
    "val_loss_data = []\n",
    "\n",
    "for key, loss in results.items():\n",
    "    if 'std' in key or 'raw' in key:\n",
    "        continue\n",
    "    \n",
    "    if 'val' in key:\n",
    "        val_loss_data.append({'data': loss, 'error': results[key + ' std'], 'label': key, 'alpha': 1.0})\n",
    "    else:\n",
    "        loss_data.append({'data': loss, 'error': results[key + ' std'], 'label': key, 'alpha': 1.0})\n",
    "        \n",
    "plot_stuff(\"val losses\", val_loss_data, figsize=(10, 14))\n",
    "plot_stuff(\"losses\", loss_data, figsize=(10, 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = create_mlp()\n",
    "cnn = create_cnn(input_shape=frames_train[0].shape)\n",
    "multi = create_multi_model(mlp, cnn)\n",
    "#multi.summary()\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(multi, to_file='../../../Downloads/multi_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
