{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from commons.configuration_manager import ConfigurationManager\n",
    "from src.learning.training.collector import Collector\n",
    "from src.learning.training.training_file_reader import TrainingFileReader\n",
    "from src.utilities.transformer import Transformer\n",
    "from src.learning.models import create_cnn, create_mlp, create_multi_model\n",
    "from notebooks.notebook_commons import read_stored_data_with_labels, create_memorized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_manager = ConfigurationManager()\n",
    "config = config_manager.config\n",
    "\n",
    "reader = TrainingFileReader(path_to_training='../../training/laps/')\n",
    "transformer = Transformer(config)\n",
    "collector = Collector()\n",
    "\n",
    "\n",
    "def plot_stuff(title, plot_elems, figsize=(18, 10)):\n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    plt.title(title)\n",
    "    #plt.ylabel('dunno')\n",
    "    plt.xlabel('Epoch')\n",
    "    x = np.arange(0, len(plot_elems[0]['data']), 1)\n",
    "    \n",
    "    for plot_elem in plot_elems:\n",
    "        plt.errorbar(x, plot_elem['data'], yerr=plot_elem['error'], label=plot_elem['label'], alpha=plot_elem['alpha'], fmt='-o', capsize=5)\n",
    "\n",
    "    plt.grid(axis='x')\n",
    "    plt.legend(loc='best', prop={'size': 15})\n",
    "    plt.show()\n",
    "    plt.savefig('./' + title + '.png')\n",
    "\n",
    "    \n",
    "filenames = ['lap_5_2020_01_24', 'lap_6_2020_01_24', 'lap_7_2020_01_24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, telems, diffs = read_stored_data_with_labels(filenames[0])\n",
    "mem_frames, mem_telems, mem_diffs = create_memorized_dataset(frames, telems, diffs, 4, 1)\n",
    "\n",
    "print(mem_frames.shape)\n",
    "print(mem_telems.shape)\n",
    "print(mem_diffs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [(1, 1), (4, 1), (8, 1), (16, 1)]\n",
    "datas_list = []\n",
    "\n",
    "for experiment in tqdm(experiments):\n",
    "    frames_mem = None\n",
    "    telemetry_mem = None\n",
    "    diffs_mem = None\n",
    "    \n",
    "    for training_file in filenames:\n",
    "        frames_i, telem_i, diffs_i = prep_full_mem_datas(*read_stored_data_with_labels(training_file), *experiment)\n",
    "        \n",
    "        if frames_mem is None and telemetry_mem is None and diffs_mem is None:\n",
    "            frames_mem = frames_i\n",
    "            telemetry_mem = telem_i\n",
    "            diffs_mem = diffs_i\n",
    "        else:\n",
    "            frames_mem = np.append(frames_mem, frames_i, axis=0)\n",
    "            telemetry_mem = np.append(telemetry_mem, telem_i, axis=0)\n",
    "            diffs_mem = np.append(diffs_mem, diffs_i, axis=0)\n",
    "        gc.collect()\n",
    "        \n",
    "    datas_list.append((frames_mem, telemetry_mem, diffs_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "verbose = 0\n",
    "\n",
    "results = {}\n",
    "\n",
    "for data in tqdm(datas_list):\n",
    "    result_desc = \"N={}, M={}\".format(*experiments[datas_list.index(data)])\n",
    "    tqdm.write(result_desc)\n",
    "    \n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    for i in tqdm(range(0, 15)):\n",
    "        frames_train, frames_test, telemetry_train, telemetry_test, diffs_train, diffs_test = train_test_split(*data, test_size=0.2)\n",
    "        \n",
    "        mlp = create_mlp(input_shape=telemetry_train[0].shape)\n",
    "        cnn = create_cnn(input_shape=frames_train[0].shape)\n",
    "        multi = create_multi_model(mlp, cnn)\n",
    "    \n",
    "        hist = multi.fit([telemetry_train, frames_train], diffs_train,\n",
    "                        validation_data=([telemetry_test, frames_test], diffs_test),\n",
    "                        epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "        \n",
    "        losses.append(hist.history['loss'])\n",
    "        val_losses.append(hist.history['val_loss'])\n",
    "    \n",
    "        gc.collect()\n",
    "    \n",
    "    mean_losses = [np.mean(i) for i in zip(*losses)]\n",
    "    std_losses = [np.std(i) for i in zip(*losses)]\n",
    "    mean_val_losses = [np.mean(i) for i in zip(*val_losses)]\n",
    "    std_val_losses = [np.std(i) for i in zip(*val_losses)]\n",
    "    \n",
    "    results[result_desc] = mean_losses\n",
    "    results[result_desc + ' std'] = std_losses\n",
    "    results[result_desc + ' val'] = mean_val_losses\n",
    "    results[result_desc + ' val std'] = std_val_losses\n",
    "    \n",
    "    tqdm.write(\"Mean loss per epoch: {}\".format(mean_losses))\n",
    "    tqdm.write(\"Mean validation loss per epoch: {}\".format(mean_val_losses))\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_data = []\n",
    "val_loss_data = []\n",
    "\n",
    "for key, loss in results.items():\n",
    "    if 'std' in key or 'raw' in key:\n",
    "        continue\n",
    "    \n",
    "    if 'val' in key:\n",
    "        val_loss_data.append({'data': loss, 'error': results[key + ' std'], 'label': key, 'alpha': 1.0})\n",
    "    else:\n",
    "        loss_data.append({'data': loss, 'error': results[key + ' std'], 'label': key, 'alpha': 1.0})\n",
    "        \n",
    "plot_stuff(\"val losses\", val_loss_data, figsize=(10, 14))\n",
    "plot_stuff(\"losses\", loss_data, figsize=(10, 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = create_mlp()\n",
    "cnn = create_cnn(input_shape=frames_train[0].shape)\n",
    "multi = create_multi_model(mlp, cnn)\n",
    "#multi.summary()\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(multi, to_file='../../../Downloads/multi_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}