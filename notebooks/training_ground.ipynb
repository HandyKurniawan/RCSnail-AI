{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div#notebook-container    { width: 75%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 75%; }\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from commons.configuration_manager import ConfigurationManager\n",
    "from src.utilities.transformer import Transformer\n",
    "from src.learning.training.generator import Generator, GenFiles\n",
    "from src.learning.models import create_cnn, create_mlp, create_multi_model, \\\n",
    "                                create_cnn_2, create_cnn_alone, create_cnn_alone_categorical, \\\n",
    "                                create_mlp_2, create_multi_model_2, create_multi_model_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stuff(title, plot_elems, figsize=(18, 10)):\n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    plt.title(title)\n",
    "    #plt.ylabel('dunno')\n",
    "    plt.xlabel('Epoch')\n",
    "    x = np.arange(0, len(plot_elems[0]['data']), 1)\n",
    "    \n",
    "    for plot_elem in plot_elems:\n",
    "        plt.errorbar(x, plot_elem['data'], yerr=plot_elem['error'], label=plot_elem['label'], alpha=plot_elem['alpha'], fmt='-o', capsize=5)\n",
    "\n",
    "    plt.grid(axis='x')\n",
    "    plt.legend(loc='best', prop={'size': 15})\n",
    "    plt.show()\n",
    "    plt.savefig('./' + title + '.png')\n",
    "    \n",
    "def get_model_num(model_path, model_prefix):\n",
    "    model_files = [fn for fn in os.listdir(model_path) if fn.startswith(model_prefix) and fn.endswith('.h5')]\n",
    "    ordered_files = sorted(model_files, key=str.lower)\n",
    "    # expected format is \"model_n1_m1_9.h5\"\n",
    "    latest_num = ordered_files[-1].split('_')[3].split('.')[0]\n",
    "    return int(latest_num) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_manager = ConfigurationManager()\n",
    "config = config_manager.config\n",
    "\n",
    "memory_variants = [(1, 1), (4, 1), (8, 1)]\n",
    "memory_variants = memory_variants[0:2]\n",
    "#memory = memory_variants[1]\n",
    "\n",
    "model_path = '../../training/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model experiments\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "verbose = 1\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "generator = Generator(config, memory_tuple=memory, base_path='../../training/', batch_size=batch_size, column_mode='steer', separate_files=True)\n",
    "frame_shape, numeric_shape, diff_shape = generator.get_shapes()\n",
    "print(frame_shape)\n",
    "print(numeric_shape)\n",
    "print(diff_shape)\n",
    "\n",
    "models = []\n",
    "\n",
    "mlp = create_mlp_2(input_shape=numeric_shape)\n",
    "cnn = create_cnn_2(input_shape=frame_shape)\n",
    "models.append((create_multi_model_2(mlp, cnn, output_shape=diff_shape), generator.generate_with_numeric))\n",
    "\n",
    "models.append((create_cnn_alone(input_shape=frame_shape, output_shape=diff_shape), generator.generate))\n",
    "\n",
    "for model, generate_method in tqdm(models):\n",
    "    result_desc = 'n{}_m{}'.format(*memory)\n",
    "    tqdm.write(result_desc)\n",
    "\n",
    "    hist = model.fit(generate_method(data='train'),\n",
    "                     steps_per_epoch=generator.train_batch_count,\n",
    "                     validation_data=generate_method(data='test'),\n",
    "                     validation_steps=generator.test_batch_count,\n",
    "                     epochs=epochs, verbose=verbose)\n",
    "\n",
    "    model_file_prefix = 'model_n{}_m{}'.format(*memory)\n",
    "    model_file_suffix = '_{}.{}'\n",
    "\n",
    "    model_number = get_model_num(model_path, model_file_prefix)\n",
    "    plot_model(model, to_file=model_path + model_file_prefix + model_file_suffix.format(model_number, 'png'), show_shapes=True)\n",
    "    model.save(model_path + model_file_prefix + model_file_suffix.format(model_number, 'h5'))\n",
    "    \n",
    "    current_loss = hist.history['loss']\n",
    "    current_val_loss = hist.history['val_loss'] \n",
    "    \n",
    "    losses.append(current_loss)\n",
    "    val_losses.append(current_val_loss)\n",
    "    \n",
    "    tqdm.write(\"Loss per epoch: {}\".format(current_loss))\n",
    "    tqdm.write(\"Validation loss per epoch: {}\".format(current_val_loss))\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ec419ef21b400982701f5186d4d340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n1_m1\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../training/n1_m1/steer_sample_n1_m1.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-73e6cb5dd6c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../../training/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mframe_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Target shape: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/RCSnail-AI/src/learning/training/generator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, memory_tuple, base_path, batch_size, column_mode, test_size)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__apply_upsampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/RCSnail-AI/src/learning/training/generator.py\u001b[0m in \u001b[0;36m__apply_upsampling\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'steer'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0msampling_multipliers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mGenFiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteer_sampling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msampling_multipliers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Indexes and sampling shape mismatch!'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python37/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../training/n1_m1/steer_sample_n1_m1.npy'"
     ]
    }
   ],
   "source": [
    "# Memory experiments on steering + throttle models\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "verbose = 1\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "    \n",
    "for memory in tqdm(memory_variants):\n",
    "    result_desc = 'n{}_m{}'.format(*memory)\n",
    "    tqdm.write(result_desc)\n",
    "    \n",
    "    generator = Generator(config, memory_tuple=memory, base_path='../../training/', batch_size=batch_size, column_mode='steer')\n",
    "    frame_shape, numeric_shape, diff_shape = generator.get_shapes()\n",
    "    tqdm.write('Target shape: {}'.format(diff_shape))\n",
    "    tqdm.write('Input shapes: {}; {}'.format(frame_shape, numeric_shape))\n",
    "    \n",
    "    #model = create_cnn_alone(input_shape=frame_shape, output_shape=diff_shape)\n",
    "    \n",
    "    mlp = create_mlp_2(input_shape=numeric_shape)\n",
    "    cnn = create_cnn_2(input_shape=frame_shape)\n",
    "    model = create_multi_model_2(mlp, cnn, output_shape=diff_shape)\n",
    "\n",
    "    hist = model.fit(generator.generate_with_numeric(data='train'),\n",
    "                     steps_per_epoch=generator.train_batch_count,\n",
    "                     validation_data=generator.generate_with_numeric(data='test'),\n",
    "                     validation_steps=generator.test_batch_count,\n",
    "                     epochs=epochs, verbose=verbose)\n",
    "\n",
    "    model_file_prefix = 'model_n{}_m{}'.format(*memory)\n",
    "    model_file_suffix = '_{}.{}'\n",
    "\n",
    "    model_number = get_model_num(model_path, model_file_prefix)\n",
    "    plot_model(model, to_file=model_path + model_file_prefix + model_file_suffix.format(model_number, 'png'), show_shapes=True)\n",
    "    model.save(model_path + model_file_prefix + model_file_suffix.format(model_number, 'h5'))\n",
    "    \n",
    "    current_loss = hist.history['loss']\n",
    "    current_val_loss = hist.history['val_loss'] \n",
    "    \n",
    "    losses.append(current_loss)\n",
    "    val_losses.append(current_val_loss)\n",
    "    \n",
    "    tqdm.write(\"Loss per epoch: {}\".format(current_loss))\n",
    "    tqdm.write(\"Validation loss per epoch: {}\".format(current_val_loss))\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory experiments on gear models\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "verbose = 1\n",
    "\n",
    "gear_losses = []\n",
    "gear_val_losses = []\n",
    "    \n",
    "for memory in tqdm(memory_variants):\n",
    "    result_desc = 'n{}_m{}'.format(*memory)\n",
    "    tqdm.write(result_desc)\n",
    "    \n",
    "    generator = Generator(config, memory_tuple=memory, base_path='../../training/', batch_size=batch_size, column_mode='all')\n",
    "    frame_shape, numeric_shape, diff_shape = generator.get_shapes()\n",
    "    tqdm.write('Target shape: {}'.format(diff_shape))\n",
    "    tqdm.write('Input shapes: {}; {}'.format(frame_shape, numeric_shape))\n",
    "    \n",
    "    mlp = create_mlp_2(input_shape=numeric_shape)\n",
    "    cnn = create_cnn_2(input_shape=frame_shape)\n",
    "    gear_model = create_multi_model_2(mlp, cnn, output_shape=2)\n",
    "\n",
    "    hist = gear_model.fit(generator.generate_with_numeric(data='train'),\n",
    "                          steps_per_epoch=generator.train_batch_count,\n",
    "                          validation_data=generator.generate_with_numeric(data='test'),\n",
    "                          validation_steps=generator.test_batch_count,\n",
    "                          epochs=epochs, verbose=verbose)\n",
    "\n",
    "    model_file_prefix = 'gear_model_n{}_m{}'.format(*memory)\n",
    "    model_file_suffix = '_{}.{}'\n",
    "\n",
    "    model_number = get_model_num(model_path, model_file_prefix)\n",
    "    plot_model(gear_model, to_file=model_path + model_file_prefix + model_file_suffix.format(model_number, 'png'), show_shapes=True)\n",
    "    gear_model.save(model_path + model_file_prefix + model_file_suffix.format(model_number, 'h5'))\n",
    "    \n",
    "    current_loss = hist.history['loss']\n",
    "    current_val_loss = hist.history['val_loss'] \n",
    "    \n",
    "    gear_losses.append(current_loss)\n",
    "    gear_val_losses.append(current_val_loss)\n",
    "    \n",
    "    tqdm.write(\"Loss per epoch: {}\".format(current_loss))\n",
    "    tqdm.write(\"Validation loss per epoch: {}\".format(current_val_loss))\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_data = []\n",
    "val_loss_data = []\n",
    "\n",
    "for i in range(0, len(losses)):\n",
    "    val_loss_data.append({'data': val_losses[i], 'label': key, 'alpha': 1.0})\n",
    "    loss_data.append({'data': losses[i], 'label': key, 'alpha': 1.0})\n",
    "        \n",
    "plot_stuff(\"val losses\", val_loss_data, figsize=(10, 14))\n",
    "plot_stuff(\"losses\", loss_data, figsize=(10, 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "generator = Generator(config, memory_tuple=memory, base_path='../../training/', batch_size=32, column_mode='steer', separate_files=True)\n",
    "frame_shape, numeric_shape, diff_shape = generator.get_shapes()\n",
    "\n",
    "shapes = ([50, 180, 12], ())\n",
    "types = (np.float32, np.float32)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(generator.generate_single_train, output_types=types, output_shapes=shapes)\n",
    "train_dataset = train_dataset.batch(batch_size=32)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(generator.generate_single_test, output_types=types, output_shapes=shapes)\n",
    "val_dataset = val_dataset.batch(batch_size=32)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=10)\n",
    "\n",
    "model = create_cnn_alone(input_shape=frame_shape, output_shape=diff_shape)\n",
    "\n",
    "hist = model.fit(train_dataset,\n",
    "                 steps_per_epoch=generator.train_batch_count,\n",
    "                 validation_data=val_dataset,\n",
    "                 validation_steps=generator.test_batch_count,\n",
    "                 epochs=10, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
